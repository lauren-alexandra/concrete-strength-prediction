{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T09:31:50.875884Z",
     "start_time": "2020-10-25T09:31:49.451304Z"
    }
   },
   "source": [
    "## Concrete Strength Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective \n",
    "\n",
    "To predict the concrete strength using the data available in file \"concrete.csv\". Apply feature engineering and model tuning to obtain a score above 85%.\n",
    "\n",
    "#### Attributes\n",
    "\n",
    "Given are the variable name, variable type, the measurement unit, and a brief description. The concrete compressive strength is the regression problem. The order of this listing corresponds to the order of numerals along the rows of the database.\n",
    "\n",
    "\n",
    "Name\t                               \n",
    "1.\tCement (cement)\t                        \n",
    "2.\tBlast Furnace Slag (slag)\t            \n",
    "3.\tFly Ash (ash)\t                      \n",
    "4.\tWater(water)\t                        \n",
    "5.\tSuperplasticizer (superplastic)\t       \n",
    "6.\tCoarse Aggregate (coarseagg)\t       \n",
    "7.\tFine Aggregate (fineagg)\t           \n",
    "8.\tAge(age)\t                         \n",
    "9.\tConcrete compressive strength(strength)\t\n",
    "\n",
    "Data Type\n",
    "1. quantitative\n",
    "2. quantitative\n",
    "3. quantitative\n",
    "4. quantitative\n",
    "5. quantitative\n",
    "6. quantitative\n",
    "7. quantitative\n",
    "8. quantitative\n",
    "9. quantitative\n",
    "\n",
    "Measurement\n",
    "1. kg in a m3 mixture\n",
    "2. kg in a m3 mixture\n",
    "3. kg in a m3 mixture\n",
    "4. kg in a m3 mixture\n",
    "5. kg in a m3 mixture\n",
    "6. kg in a m3 mixture\n",
    "7. kg in a m3 mixture\n",
    "8. kg in a m3 mixture\n",
    "9. kg in a m3 mixture\n",
    "\n",
    "Description\n",
    "1. Input Variable\n",
    "2. Input Variable\n",
    "3. Input Variable\n",
    "4. Input Variable\n",
    "5. Input Variable\n",
    "6. Input Variable\n",
    "7. Input Variable\n",
    "8. Input Variable\n",
    "9. Output Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Quality Report\n",
    "\n",
    "1. Univariate analysis â€“data types and description of the independent attributes which should include (name, range of values observed, central values (mean and median), standard deviation and quartiles, analysis of the body of distributions/tails, missing values, outliers, duplicates(10 Marks)\n",
    "\n",
    "2. Bi-variate analysis between the predictor variables and between the predictor variables and target column. Comment on your findings in terms of their relationship and degree of relation if any. Visualize the analysis using boxplots and pair plots, histograms, or density curves. (10 marks)\n",
    "\n",
    "3. Feature Engineering techniques(10 marks)\n",
    "   1. Identify opportunities (if any) to extract new features from existing features, drop a feature(if required) Hint: Feature Extraction, for example, consider a dataset with two features length and breadth. From this, we can extract a new feature Area which would be length * breadth.\n",
    "   \n",
    "  2. Get the data model ready and do a train test split.\n",
    "  \n",
    "  3. Decide on the complexity of the model, should it be a simple linear model in terms of parameters or would a quadratic or higher degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model and Tuning It\n",
    "\n",
    "1. Algorithms that you think will be suitable for this project. Use Kfold Cross-Validation to evaluate model performance. Use appropriate metrics and make a DataFrame to compare models w.r.t their metrics. (at least 3 algorithms, one bagging and one boosting based algorithms have to be there). (15 marks)\n",
    "\n",
    "2. Techniques employed to squeeze that extra performance out of the model without making it overfit. Use Grid Search or Random Search on any of the two models used above. Make a DataFrame to compare models after hyperparameter tuning and their metrics as above. (15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
